{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOBUyiZq3d2u"
   },
   "source": [
    "# Praktische Übung 6: Neural Networks - Lösung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhdvnPe4Q-pO"
   },
   "source": [
    "### 0. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K8-YOrlu3w8z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines checks for GPU availability on the machine and sets the GPU as processing device (if available). If you are on Google Colab you can enable GPU support in the menu via `Runtime > Change runtime type` and select `GPU` as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3DgoJj735Gr",
    "outputId": "e56e337f-c44f-4bc3-c1ae-e532bb999356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "  processing_chip = \"cuda:0\"\n",
    "  print(f\"{torch.cuda.get_device_name(0)} available\")\n",
    "else:\n",
    "  processing_chip = \"cpu\"\n",
    "  print(\"No GPU available\")\n",
    "\n",
    "device = torch.device(processing_chip)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8EgmXccAr9b"
   },
   "source": [
    "### 1. Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with the already know digit dataset. For more details on the dataset, check our [previous](https://github.com/pabair/ml-kurs-ss21/blob/master/2_Logistische_Regression_Digits.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DZoYUZfQ_TU8"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data, labels = load_digits(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KfY2iF0WTlWu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQqdZZ16AHBe",
    "outputId": "75f7aff9-a647-4010-bafa-8141fc7aa46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ..., 16., 16.,  6.],\n",
       "       [ 0.,  3., 12., ..., 16.,  2.,  0.],\n",
       "       [ 0.,  1., 10., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., ..., 11.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use the data in PyTorch, we need to convert them into PyTorch tensors. Such a tensor can be thought of an efficient way to represent lists and matrices (similar to Numpy), with the additional benefit that they can be moved to the GPU (the .to(device) part in the code below) and that they support automatic backpropagation (more on this later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_X).float().to(device)\n",
    "test_x = torch.Tensor(test_X).float().to(device)\n",
    "train_y =torch.Tensor(train_y).long().to(device)\n",
    "test_y = torch.Tensor(test_y).long().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wcTXnyu7NWK"
   },
   "source": [
    "### 2. Model definition \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now the strucutre of our neural network. For this we create a class that is a subclass from PyTorch's nn.Module. By convention we put in the `__init__` method the layers we want to use in the network and in the `forward` method how data flows through this network.\n",
    "\n",
    "Our network has 64 input features, one hidden layer with 5 neurons and 10 output neurons. The hidden layer uses a Relu activation function. Note that the output layer does not have a softmax activation (unlike we have seen it in the lecture). It rather gives out a raw score for each class (more on this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_W47oZ534E-1"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hidden1 = nn.Linear(64, 10) # Task 1\n",
    "    self.hidden2 = nn.Linear(10, 5)  # Task 1\n",
    "    self.output = nn.Linear(5, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = F.relu(self.hidden1(x))\n",
    "    z = F.relu(self.hidden2(z)) # Task 1\n",
    "    z = self.output(z)  # no softmax. see CrossEntropyLoss() \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJyy5JG_84vs"
   },
   "source": [
    "### 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training our network. We run several epochs in which we first predict on the training data with our network and than backpropagate the loss. For this we use PyTorch's build-in optimizer that runs gradient descent on the weights of the network. Hence, in every episode we reduce the loss on the training data and improve our network.\n",
    "\n",
    "As loss function we use cross entropy, which consumes the raw scores from the prediction and internally applies a softmax (that is why we do not need the softmax as last layer in the network).\n",
    "\n",
    "Note that all training data is passed at once to our network (line `net(train_x)` ), since PyTorch will predict on all data points in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden1): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (hidden2): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (output): Linear(in_features=5, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create network, move it to device and set it to training-mode\n",
    "net = Net().to(device)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RQHZvvyAFzV",
    "outputId": "85c7caef-49ee-443f-d052-30af1758c4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training \n",
      "Loss in epoch 0 is 2.768087387084961\n",
      "Loss in epoch 100 is 1.8456432819366455\n",
      "Loss in epoch 200 is 1.5123120546340942\n",
      "Loss in epoch 300 is 1.283310890197754\n",
      "Loss in epoch 400 is 1.1420927047729492\n",
      "Loss in epoch 500 is 0.9864488244056702\n",
      "Loss in epoch 600 is 0.7818663716316223\n",
      "Loss in epoch 700 is 0.6709215044975281\n",
      "Loss in epoch 800 is 0.5803940892219543\n",
      "Loss in epoch 900 is 0.4972643256187439\n",
      "Loss in epoch 1000 is 0.4304571747779846\n",
      "Loss in epoch 1100 is 0.37476667761802673\n",
      "Loss in epoch 1200 is 0.3190990090370178\n",
      "Loss in epoch 1300 is 0.26466989517211914\n",
      "Loss in epoch 1400 is 0.22832602262496948\n",
      "Loss in epoch 1500 is 0.20401905477046967\n",
      "Loss in epoch 1600 is 0.18581870198249817\n",
      "Loss in epoch 1700 is 0.17134864628314972\n",
      "Loss in epoch 1800 is 0.15933029353618622\n",
      "Loss in epoch 1900 is 0.14909332990646362\n",
      "Loss in epoch 2000 is 0.14020377397537231\n",
      "Loss in epoch 2100 is 0.13237212598323822\n",
      "Loss in epoch 2200 is 0.12521572411060333\n",
      "Loss in epoch 2300 is 0.1187385767698288\n",
      "Loss in epoch 2400 is 0.11281826347112656\n",
      "Loss in epoch 2500 is 0.10742434114217758\n",
      "Loss in epoch 2600 is 0.1024484634399414\n",
      "Loss in epoch 2700 is 0.097802072763443\n",
      "Loss in epoch 2800 is 0.09344605356454849\n",
      "Loss in epoch 2900 is 0.08937712013721466\n",
      "Loss in epoch 3000 is 0.08558943122625351\n",
      "Loss in epoch 3100 is 0.08196908235549927\n",
      "Loss in epoch 3200 is 0.07857124507427216\n",
      "Loss in epoch 3300 is 0.07544279098510742\n",
      "Loss in epoch 3400 is 0.07253368198871613\n",
      "Loss in epoch 3500 is 0.06982209533452988\n",
      "Loss in epoch 3600 is 0.06719423085451126\n",
      "Loss in epoch 3700 is 0.06472761183977127\n",
      "Loss in epoch 3800 is 0.06242461875081062\n",
      "Loss in epoch 3900 is 0.06027626618742943\n",
      "Loss in epoch 4000 is 0.058243025094270706\n",
      "Loss in epoch 4100 is 0.05632650479674339\n",
      "Loss in epoch 4200 is 0.054510265588760376\n",
      "Loss in epoch 4300 is 0.05277780443429947\n",
      "Loss in epoch 4400 is 0.051136307418346405\n",
      "Loss in epoch 4500 is 0.04957843944430351\n",
      "Loss in epoch 4600 is 0.04808910936117172\n",
      "Loss in epoch 4700 is 0.04665924236178398\n",
      "Loss in epoch 4800 is 0.045289743691682816\n",
      "Loss in epoch 4900 is 0.0439758338034153\n",
      "Loss in epoch 5000 is 0.04268604889512062\n",
      "Loss in epoch 5100 is 0.04143339395523071\n",
      "Loss in epoch 5200 is 0.040118664503097534\n",
      "Loss in epoch 5300 is 0.03867695853114128\n",
      "Loss in epoch 5400 is 0.03734274208545685\n",
      "Loss in epoch 5500 is 0.036030370742082596\n",
      "Loss in epoch 5600 is 0.03480686992406845\n",
      "Loss in epoch 5700 is 0.03365560993552208\n",
      "Loss in epoch 5800 is 0.03256037086248398\n",
      "Loss in epoch 5900 is 0.0315113440155983\n",
      "Loss in epoch 6000 is 0.030518198385834694\n",
      "Loss in epoch 6100 is 0.029568446800112724\n",
      "Loss in epoch 6200 is 0.028656436130404472\n",
      "Loss in epoch 6300 is 0.027776142582297325\n",
      "Loss in epoch 6400 is 0.02693905495107174\n",
      "Loss in epoch 6500 is 0.02612435817718506\n",
      "Loss in epoch 6600 is 0.02534148283302784\n",
      "Loss in epoch 6700 is 0.024592511355876923\n",
      "Loss in epoch 6800 is 0.023874109610915184\n",
      "Loss in epoch 6900 is 0.023190539330244064\n",
      "Loss in epoch 7000 is 0.022528639063239098\n",
      "Loss in epoch 7100 is 0.02189761772751808\n",
      "Loss in epoch 7200 is 0.02128484472632408\n",
      "Loss in epoch 7300 is 0.02070128172636032\n",
      "Loss in epoch 7400 is 0.02013092115521431\n",
      "Loss in epoch 7500 is 0.019585736095905304\n",
      "Loss in epoch 7600 is 0.0190647691488266\n",
      "Loss in epoch 7700 is 0.018558312207460403\n",
      "Loss in epoch 7800 is 0.018076032400131226\n",
      "Loss in epoch 7900 is 0.017608458176255226\n",
      "Loss in epoch 8000 is 0.017158709466457367\n",
      "Loss in epoch 8100 is 0.016727186739444733\n",
      "Loss in epoch 8200 is 0.016307346522808075\n",
      "Loss in epoch 8300 is 0.015906017273664474\n",
      "Loss in epoch 8400 is 0.01551785971969366\n",
      "Loss in epoch 8500 is 0.015146980062127113\n",
      "Loss in epoch 8600 is 0.01478295773267746\n",
      "Loss in epoch 8700 is 0.01443014107644558\n",
      "Loss in epoch 8800 is 0.01409091055393219\n",
      "Loss in epoch 8900 is 0.013759731315076351\n",
      "Loss in epoch 9000 is 0.013442645780742168\n",
      "Loss in epoch 9100 is 0.013134857639670372\n",
      "Loss in epoch 9200 is 0.012839115224778652\n",
      "Loss in epoch 9300 is 0.012552355416119099\n",
      "Loss in epoch 9400 is 0.012275789864361286\n",
      "Loss in epoch 9500 is 0.012007877230644226\n",
      "Loss in epoch 9600 is 0.01174953393638134\n",
      "Loss in epoch 9700 is 0.01149971317499876\n",
      "Loss in epoch 9800 is 0.011256360448896885\n",
      "Loss in epoch 9900 is 0.011022098362445831\n",
      "Done training \n"
     ]
    }
   ],
   "source": [
    "# create network, move it to device and set it to training-mode\n",
    "net = Net().to(device)\n",
    "net.train()\n",
    "\n",
    "# define the parameters for training\n",
    "no_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "loss_func = nn.CrossEntropyLoss()  # applies softmax() internally\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nStarting training \")\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(0, no_epochs):\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  output = net(train_x)\n",
    "\n",
    "  loss = loss_func(output, train_y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  y_hat_test = net(test_x)\n",
    "  loss_test = loss_func(y_hat_test, test_y)\n",
    "\n",
    "  train_losses.append(loss.item())\n",
    "  test_losses.append(loss_test.item())\n",
    "  \n",
    "  if epoch % 100 == 0:\n",
    "    print(f\"Loss in epoch {epoch} is {loss.item()}\")\n",
    "\n",
    "print(\"Done training \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "fMPxG1i873W7",
    "outputId": "8ed83937-f40a-4e0e-a259-e409fff8fc9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAp1UlEQVR4nO3deXhV1bnH8e+bGUIAgcgUlEGxIkPACIKKKLdOiFpqW9s6tbXUtpaq17Fq67XjbftUpfZKua3SwavWFhAFJxwK1oECRQUBQQaJaMEoIWFMyLp/rH3IIZzMOdkn2b/P8+xnz+e8O+h+z15r7bXMOYeIiERXWtgBiIhIuJQIREQiTolARCTilAhERCJOiUBEJOIywg6gsXr06OH69+8fdhgiIm3KsmXLPnLO5Sfa1+YSQf/+/Vm6dGnYYYiItClmtrm2fSoaEhGJOCUCEZGIUyIQEYm4NldHICLtS0VFBcXFxezduzfsUNqFnJwcCgoKyMzMbPA5SgQiEqri4mLy8vLo378/ZhZ2OG2ac46SkhKKi4sZMGBAg89T0ZCIhGrv3r10795dSaAFmBndu3dv9NOVEoGIhE5JoOU05W8ZmUSwciXccQds2xZ2JCIiqSUyieDtt+FHP4Lt28OORERSSUlJCYWFhRQWFtKrVy/69u17cH3//v11nrt06VKmTZvWqO/r378/H330UXNCbnGRqSxOC1KexuERkXjdu3dnxYoVANx555106tSJG2644eD+yspKMjIS3yqLioooKipqjTCTKjJPBLFis6qqcOMQkdR35ZVXcv3113PGGWdw8803s2TJEsaNG8fIkSMZN24ca9euBeCll17i/PPPB3wS+epXv8qECRMYOHAg06dPb/D3bd68mYkTJzJ8+HAmTpzIe++9B8Bjjz3G0KFDGTFiBOPHjwdg1apVjB49msLCQoYPH866deuafb2ReSKIJQI9EYikrmuvheDHeYspLIR77mn8ee+88w4LFy4kPT2dnTt3smjRIjIyMli4cCHf+973+Nvf/nbYOWvWrOHFF1+krKyM4447jm9+85sNas9/zTXXcPnll3PFFVfwwAMPMG3aNObOnctdd93FM888Q9++fdmxYwcAM2bM4Lvf/S5f/vKX2b9/PwcOHGj8xdWgRCAiksDnPvc50tPTASgtLeWKK65g3bp1mBkVFRUJz5k0aRLZ2dlkZ2dz5JFH8u9//5uCgoJ6v+vVV19l9uzZAFx22WXcdNNNAJxyyilceeWVfP7zn2fKlCkAjB07lh//+McUFxczZcoUjj322GZfa2QSgeoIRFJfU365J0tubu7B5TvuuIMzzjiDOXPmsGnTJiZMmJDwnOzs7IPL6enpVFZWNum7Y01AZ8yYweuvv878+fMpLCxkxYoVfOlLX2LMmDHMnz+fs88+m9/97neceeaZTfqeGNURiIjUo7S0lL59+wIwa9asFv/8cePG8cgjjwDw0EMPceqppwLw7rvvMmbMGO666y569OjBli1b2LBhAwMHDmTatGlccMEFvPnmm83+/sglAj0RiEhj3XTTTdx6662ccsopLVImP3z4cAoKCigoKOD6669n+vTpPPjggwwfPpw//elP3HvvvQDceOONDBs2jKFDhzJ+/HhGjBjBo48+ytChQyksLGTNmjVcfvnlzY7HXBu7MxYVFbmmDEzz5JMweTIsWQInnZSEwESkSVavXs3xxx8fdhjtSqK/qZktc84lbOsamScC1RGIiCQWmUSgOgIRkcQilwj0RCAiciglAhGRiItMIlAdgYhIYpFJBPmvzuNDepK9aW3YoYiIpJTIvFmcfmA/PdnGllpeDReRaCopKWHixIkAfPjhh6Snp5Ofnw/AkiVLyMrKqvP8l156iaysLMaNG3fYvlmzZrF06VLuu+++lg+8BSUtEZhZP+CPQC+gCpjpnLu3xjETgMeBjcGm2c65u5ISUKxsqAVeBhGR9qO+bqjr89JLL9GpU6eEiaCtSGbRUCXwn86544GTgW+b2ZAExy12zhUGU3KSAEDQeZTaj4pIfZYtW8bpp5/OiSeeyNlnn80HH3wAwPTp0xkyZAjDhw/nkksuYdOmTcyYMYO7776bwsJCFi9e3KDP/9WvfsXQoUMZOnQo9wQdLO3atYtJkyYxYsQIhg4dyqOPPgrALbfccvA7G5OgGiNpTwTOuQ+AD4LlMjNbDfQF3k7Wd9bF0n3Oc5V6IhBJWSnQD7Vzju985zs8/vjj5Ofn8+ijj3LbbbfxwAMP8LOf/YyNGzeSnZ3Njh076Nq1K1dffXWjniKWLVvGgw8+yOuvv45zjjFjxnD66aezYcMG+vTpw/z58wHfv9HHH3/MnDlzWLNmDWZ2sCvqltYqlcVm1h8YCbyeYPdYM3vDzJ4ysxNqOX+qmS01s6XbmzjWpNMTgYg0wL59+1i5ciWf/vSnKSws5Ec/+hHFxcWA7yPoy1/+Mn/+859rHbWsPi+//DKf+cxnyM3NpVOnTkyZMoXFixczbNgwFi5cyM0338zixYvp0qULnTt3Jicnh6uuuorZs2fTsWPHlrzUg5JeWWxmnYC/Adc653bW2L0cONo5V25m5wFzgcM613bOzQRmgu9rqElxqI5AJPWlQD/UzjlOOOEEXn311cP2zZ8/n0WLFjFv3jx++MMfsmrVqiZ9fiKDBw9m2bJlLFiwgFtvvZWzzjqL73//+yxZsoTnn3+eRx55hPvuu48XXnih0d9Zn6Q+EZhZJj4JPOScm11zv3Nup3OuPFheAGSaWY+kBJMRPBEoEYhIHbKzs9m+ffvBRFBRUcGqVauoqqpiy5YtnHHGGfz85z9nx44dlJeXk5eXR1lZWYM/f/z48cydO5fdu3eza9cu5syZw2mnncbWrVvp2LEjl156KTfccAPLly+nvLyc0tJSzjvvPO65556DldotLZmthgz4PbDaOferWo7pBfzbOefMbDQ+MZUkJZ7gicAdUNGQiNQuLS2Nv/71r0ybNo3S0lIqKyu59tprGTx4MJdeeimlpaU457juuuvo2rUrkydP5uKLL+bxxx/n17/+Naeddtohnzdr1izmzp17cP21117jyiuvZPTo0QBcddVVjBw5kmeeeYYbb7yRtLQ0MjMzuf/++ykrK+PCCy9k7969OOe4++67k3LNSeuG2sxOBRYDb+GbjwJ8DzgKwDk3w8yuAb6Jb2G0B7jeOfdKXZ/b1G6oV/3mJU645gyW/OwFRt98RqPPF5HkUDfULa+x3VAns9XQy4DVc8x9QOu8aaHKYhGRhCLTxYReKBMRSSwyicCCymLVEYiknrY2UmIqa8rfMjqJIF1PBCKpKCcnh5KSEiWDFuCco6SkhJycnEadF5lO51RHIJKaCgoKKC4upqkvi8qhcnJyKCgoaNQ50UkEqiMQSUmZmZkMGDAg7DAiLTpFQxl6IhARSSQ6iUCdzomIJBSZRJDd0T8RVO7XE4GISLzIJIKcTr46ZP8ujVAmIhIvMomgw5F5fqERnUOJiERBdBJBz85+YWfNnrBFRKItMokgq0sHKkknrVyJQEQkXmQSAWaUWWdMiUBE5BDRSQRAeXpX0ks/CTsMEZGUEqlE8EmH3uSWbg07DBGRlBKpRFDeuS9dd78fdhgiIiklUolgT/e+5O9/H9TLoYjIQZFKBFW9+tKJXVSUqMJYRCQmUonA+vmuWT9+szjkSEREUkekEkHWoH4AlL29JeRIRERSR6QSQe6nfCLYs06JQEQkJlKJ4IgT+nCANA5sUiIQEYmJVCLo2TeDrfQh7X0lAhGRmEglgtxc2JrWj5xt74UdiohIyohUIgD4qEM/8nboiUBEJCZyiaC0Sz+67dqil8pERAKRSwR7e/Qju2ovlJSEHYqISEpIWiIws35m9qKZrTazVWb23QTHmJlNN7P1ZvammY1KVjwxlb19E1K2qHhIRASS+0RQCfync+544GTg22Y2pMYx5wLHBtNU4P4kxuMddZQPbqMSgYgIJDEROOc+cM4tD5bLgNVA3xqHXQj80XmvAV3NrHeyYgLIPsY/EZSvVsshERFopToCM+sPjARer7GrLxD/07yYw5MFZjbVzJaa2dLt27c3K5bOg/LZRxb79HaxiAjQConAzDoBfwOudc7V7PbTEpxyWHMe59xM51yRc64oPz+/WfH06pNGMQV6u1hEJJDURGBmmfgk8JBzbnaCQ4qBfnHrBUBShxDr1Qu20I+0rUoEIiKQ3FZDBvweWO2c+1Uth80DLg9aD50MlDrnPkhWTAC9e/tEkLNdiUBEBCAjiZ99CnAZ8JaZrQi2fQ84CsA5NwNYAJwHrAd2A19JYjwA5OTA9ux+5JUWw4EDkJ6e7K8UEUlpSUsEzrmXSVwHEH+MA76drBhqU3bEUaR/eAA+/BD6HlY3LSISKZF7sxhg35F6qUxEJCaSicAVKBGIiMREMhFkDvSJwL2nRCAiEslE0LV/V8rJZd86vV0sIhLJRNC7j7GFfux/V08EIiLRTAS9YSMDYNPGsEMREQldZBPBeo6hQ/E6DVAjIpEX2USwjmPJ3FsO27aFHY6ISKgimQjy8qA4+xi/sm5duMGIiIQskonADPb2O9avrF8fbjAiIiGLZCIAyDzmaCpJ1xOBiEReZBNBv4GZbE4boCcCEYm8yCaCAQPgnapjqFyjJwIRibbIJoL+/X3LIXt3vZqQikikRT4RpO8qUxNSEYm0SCeC9QRNSFVPICIRFtlE0L07vN8haEKqlkMiEmGRTQRmkD7waA6YmpCKSLRFNhGAb0JanKkmpCISbZFOBIMGwdoDx+D0RCAiERb5RLDmwLG4dWpCKiLRFflEsJ5jSCtXE1IRia7IJ4J1qPM5EYm2SCeC/v3hXVMTUhGJtkgngqwsqOqnJqQiEm2RTgQARx+TSXH2IFizJuxQRERCEflEMGgQvFk1DFauDDsUEZFQJC0RmNkDZrbNzBLeYc1sgpmVmtmKYPp+smKpy6BBsGz/UNz69bBnTxghiIiEKplPBLOAc+o5ZrFzrjCY7kpiLLUaNAhWMhSrqoLVq8MIQUQkVElLBM65RcDHyfr8ljJoELzFML+i4iERiaCw6wjGmtkbZvaUmZ1Q20FmNtXMlprZ0u3bt7doAIMGwbsMojIjG956q0U/W0SkLQgzESwHjnbOjQB+Dcyt7UDn3EznXJFzrig/P79Fg+jcGbrlZ1DcdSgsX96iny0i0hY0KBGY2XfNrLN5vzez5WZ2VnO+2Dm30zlXHiwvADLNrEdzPrOpBg2CFdknw5IlcOBAGCGIiISmoU8EX3XO7QTOAvKBrwA/a84Xm1kvM7NgeXQQS0lzPrOpPvUpWFh+MpSXw6pVYYQgIhKahiYCC+bnAQ86596I25b4BLOHgVeB48ys2My+ZmZXm9nVwSEXAyvN7A1gOnCJc+F0AXrCCfBU6Vi/8uqrYYQgIhKajAYet8zMngUGALeaWR5QVdcJzrkv1rP/PuC+Bn5/Up1wAmxgIPu75pP1yivwjW+EHZKISKtpaCL4GlAIbHDO7TazbvjioXZh6FAAY8uA8Qx64QU/NoHV+cAjItJuNLRoaCyw1jm3w8wuBW4HSpMXVusqKPCth17reg4UF8Pbb4cdkohIq2loIrgf2G1mI4CbgM3AH5MWVSsz88VDc3ef7Tc8/XS4AYmItKKGJoLKoCL3QuBe59y9QF7ywmp9I0bAc2v64U44QYlARCKloYmgzMxuBS4D5ptZOpCZvLBa3+jRUFoKH485FxYtgp07ww5JRKRVNDQRfAHYh3+f4EOgL/CLpEUVgtGj/XxJn8/A/v2wYEG4AYmItJIGJYLg5v8Q0MXMzgf2OufaTR0B+JfK8vJgfsnJ0KsXzJ4ddkgiIq2ioV1MfB5YAnwO+DzwupldnMzAWlt6Opx0Ery2JA0uusg/EWh8AhGJgIYWDd0GnOScu8I5dzkwGrgjeWGFY+xYWLECdp09BXbtgueeCzskEZGka2giSHPObYtbL2nEuW3GxIm+z7mXmABdu6p4SEQioaFvFj9tZs8ADwfrXwDaXW3quHHQoQM8+2ImkyZPhnnzoKICMttVAykRkUM0tLL4RmAmMBwYAcx0zt2czMDCkJ0N48fDwoXAlCnwySfw97+HHZaISFI1uHjHOfc359z1zrnrnHNzkhlUmP7jP3wPE1uHngU5OfDEE2GHJCKSVHUmAjMrM7OdCaYyM2uXb1xNmuTn8xZ29JUGTzzhO6ETEWmn6kwEzrk851znBFOec65zawXZmj71KRg8GObOBSZPho0bYfXqsMMSEUmadtfyp7nM/GsEL7wAO08LHg+efDLUmEREkkmJIIGLLvKNhea/UQCFhUoEItKuKREkMGYM9OwZFA+dfz784x/w8cdhhyUikhRKBAmkpcGFF8JTT0HFxHOgqsr3SCoi0g4pEdRi8mQoK4O/7yryzUj1PoGItFNKBLWYONG/Zfz409lw8sl6IhCRdkuJoBYdOsBZZ/leJtwppwa90e0KOywRkRanRFCHCy6A996DTd1P9PUEb70VdkgiIi1OiaAOkyb59wqe2FLoN6xYEWY4IiJJoURQh549ffXAnxYd7bulViIQkXZIiaAekyfD0mXG/iGF8K9/hR2OiEiLUyKox8SJfr6pywhYudLXFYiItCNJSwRm9oCZbTOzlbXsNzObbmbrzexNMxuVrFiaY9QoP6j9kj3DYPdu2LAh7JBERFpUMp8IZgHn1LH/XODYYJoK3J/EWJosIwNOOw0e3zjcb3jzzXADEhFpYUlLBM65RUBdHfRcCPzRea8BXc2sd7LiaY7x42H+5hNwZmpCKiLtTph1BH2BLXHrxcG2w5jZVDNbamZLt2/f3irBxRs9GvbQkd19jlEiEJF2J8xEYAm2JRwKzDk30zlX5Jwrys/PT3JYhzvxRD/f0mWYEoGItDthJoJioF/cegGwNaRY6tS5Mxx3HKw4MAzWrfOVxiIi7USYiWAecHnQeuhkoNQ590GI8dSpqAie3z7cj1/89tthhyMi0mKS2Xz0YeBV4DgzKzazr5nZ1WZ2dXDIAmADsB74X+BbyYqlJZx0Erz08TC/ouIhEWlHMpL1wc65L9az3wHfTtb3t7QTT4QNDORAdgfSlQhEpB3Rm8UNNGIEOEvnwx5D9S6BiLQrSgQNlJcHgwfD6nS1HBKR9kWJoBFOPBFe3jkctm2DD1K2XltEpFGUCBph1CiYs2OCX5k/P9RYRERaihJBI4waBW8ynN29BsCcOWGHIyLSIpQIGmHkSABj5aCLYOFC+OSTkCMSEWk+JYJG6NoVBg2CxzpcDvv3w6xZYYckItJsSgSNNGoU/OWdQty4cfCb32igGhFp85QIGunMM+G992DrZ66Bd9+FZ58NOyQRkWZRImikSZP8/JGKz/rR7e+7L9yARESaSYmgkfr1g+HDYd7TWTB1KixYoOErRaRNUyJogilTYPFi2Dr5G5CW5usKRETaKCWCJrjsMt8b9R8W9oUvfAF++1v4uK5ROUVEUpcSQRMMHOgHtP/DH8Ddcivs2gXTp4cdlohIkygRNNGVV8LatfDyjqFw0UU+EezcGXZYIiKNpkTQRJdcAkccAb/+NXDbbf4t47vvDjssEZFGUyJooo4d4etfh9mzYUvPIrj4YvjlL33PpCIibYgSQTN861u+0vh//gf48Y9hzx740Y/CDktEpFGUCJrh6KN99cDMmbCn32C46iqYMUPvFYhIm6JE0EzXXutbjs6aBfzgB5CZCXfcEXJUIiINp0TQTKeeCuPGwc9/DhU9evvM8H//B//6V9ihiYg0iBJBM5nB974HmzbBww8DN90E3brBLbeEHZqISIMoEbSA887z/Q/99KdQldcFbr/d90r6/PNhhyYiUi8lghYQeypYswbmzsU3Jzr6aLj5ZjhwIOzwRETqpETQQi6+GI45Bn7yE3BZ2f7xYNky/26BiEgKUyJoIenpvlpg2bJgrJpLLvHZ4fbb4Z//DDs8EZFaKRG0oMsu8+MV3HknOMz3Stq7t3/Z4P33ww5PRCShpCYCMzvHzNaa2XozO6wZjZlNMLNSM1sRTN9PZjzJlpUF3/8+vPYaPPkkvvXQk0/6zugmT4by8rBDFBE5TNISgZmlA78BzgWGAF80syEJDl3snCsMpruSFU9rueIKOPZY3w9dVRW+OdGjj8Ibb8CXvqTKYxFJOcl8IhgNrHfObXDO7QceAS5M4velhMxMuOsueOst+OMfg43nnee7qX7iCbjuOt9BkYhIikhmIugLbIlbLw621TTWzN4ws6fM7IREH2RmU81sqZkt3b59ezJibVGf/7x/2/imm+IGLvv2t+H6632/1T/5SajxiYjES2YisATbav4UXg4c7ZwbAfwamJvog5xzM51zRc65ovz8/JaNMgnS0uD++30SuO22uB2/+IWvUb79dt85nYhICkhmIigG+sWtFwBb4w9wzu10zpUHywuATDPrkcSYWs3w4TBtmm84tGRJsDEtDX7/ezj/fP/S2V/+EmqMIiKQ3ETwT+BYMxtgZlnAJcC8+APMrJeZWbA8OoinJIkxtar/+i/o08cPa7lnT7AxM9MngFNPhUsvDV46EBEJT9ISgXOuErgGeAZYDfzFObfKzK42s6uDwy4GVprZG8B04BLn2k9Nal4ePPggrF7t6wsO6tAB5s2DIUPgs5+FN98MLUYREWtr992ioiK3dOnSsMNolOuug3vugfnzfQOig95/H8aM8UVGr7/uXz4TkdTmHFRWwu7dUFHh5/v2+fmuXf7xP7a+d69f3ru3Ycv17Z82zY970gRmtsw5V5RoX0az/iDSID/9KbzwAlx+uR+moF+s5qRvX9+k9NRT4dxz4emnoVevUGMVabOcq74Bx27KseX4qbzc31T37PHH7N3rt+/Z46fy8kPXEy03932gnBzIzvbzRMt5eZCff/j2kSNb5m9VgxJBK8jJgcceg6Ii37T073/3byED/h92zhyYMgXGjoUFC+D440ONVySpKiqgrMxPsZt1bLmsrPqGvXNn9fKePdXr8cfEztm719/Aq6oaH092NnTs6ItsO3SATp38vGNH6Nq1el9snpPj57m5vs6vQwf/Gbm5/pjYjTv++Pgbemam77I4hSgRtJLBg+GBB+Bzn4Mbb4R7743bedZZ8OKLMGkSjBrl30i77jrI0D+PhKyiwt9gy8r8fOfO6uXYPNFy/I08ds6uXX6qrGz496enV99QO3WqnvLy4Mgjq9dj+2M34/hz4ucdOvhzYzfzDh180WzEqY6glcXqCx591D8dHOKDD3yz0rlz4cQT/djH55/v/2cQaYiqquqbcVnZ4Tfu2HpDpvJyX9TSEGaH3qg7doTOnf28S5fqbXl5/mbdoYPfnp3tj8vLq/6VnZdXfbPPzk7u3ytC6qojUCJoZfv3w4QJvguKpUvhuONqHOCczxI33wzvvefrDC6+2GeNU07Rr5f2xjn/H0Ws6CN2o040j5Vdl5VBaamfYr/SY/vLyxvWhUlaWvXNtrYpdlPv3Ln613anTnDEEdXnxv8i13+bKU2JIMVs2eJLgHr29I2FcnMTHFRZ6Z8MHnnENzfau9f/DzhunJ9OOQVOOsn/ypLkqfkLO9Gv6kS/suNv4Ga+cjE27d9f3Qpk166Gl2tnZVXfjDt39uXXsZt2bq7/hd25c/Uv7NgNPNG8Y8eUK6eW5FIiSEHPPQdnn+3fKfvDH+r5f7K83Hdn/fzz8I9/+BcTwNchHHOM7+508OBD5336RPcXWkVF9S/m+Jt07IYeq2BsyE29oV2Hp6VV34BrTma+eC8tzf+bZWX5KSfn8LLr2M09/mYe+5zMzKT+2aR9UyJIUXfd5ZsE//a3MHVqI04sKYFXX/XTmjXwzjuwfr3/hRnTsaNPEscc44uXevTwU/fuhy536+ZvRmH9Oqyqqm6WF6tMjF+ONefbtau66CO+OGTnTtixo3peWhr3Gnc9Ys30YlPNG3lj1jt00C9sSWlKBCmqqsq/YPbii/DKK75+uFkfVlwM69b5xBCbv/subNsGn3xSe9lxfHlxx47+BpmVVT2PLWdk+Jtd7EnDOT9VVVUXeVRUHDqvbTk2b2x77FilZF6eLwrJy/NFZp07+/UuXfyv6thy/M06Vp4dq5A82IZXpP1TIkhhH33kXyXIzPRDG3fvnqQvOnDAJ4OPPvJTSYmff/xxdaVjrNnfvn3VN+5YeXbs5h278UN1UogVfcSSRlaWv6CGLMfaYcea/MWa/8Vu2LHik/hKSf3yFmk0vVmcwnr08C+bnX66f53gued8aU2LS0+vLhISEYkT0drE1HLyyf7l4pUr4bTTYOPGsCMSkShRIkgR550HTz0FW7f6fuieeCLsiEQkKpQIUsiZZ8Jrr/lOSC+4AL74RT0diEjyKRGkmOOO85XGP/iBf5/suOP8cMfr14cdmYi0V0oEKSgrC+6809/8v/IVmDnTvyc2aRI8/njDu38REWkIJYIU1revf9ls82bf/9yyZXDRRb5riq9+1fdYvXt32FGKSFun9wjakIoKWLjQdz80Z45v9p+dDePH++4qzjwThg1T79Uicji9UNYO7d0LixbBM8/4adUqvz0317c6GjvWTyNH+spnvYMlEm1KBBFQXAyLF/vuh155BVasqO69oUcPGDGiehoyxNc5dO4casgi0oqUCCJo1y5fp/DGG9XTypWH9kvXq5dvlRQ/9e8PRx/te3MQkfZDXUxEUG6urzsYP756W2Wl74tuzRpYu7Z6+utffZdD8bp39wkhNsUSREGBL2rq2VN1ESLthf5XjpCMDDj+eD/V9NFHvrPSzZth0yY/37zZJ42nnz68Z2czP2Rs795+6IPevQ+d8vN9n0nduvnOQTXioEjqUiIQoLo/unHjDt/nnE8UmzfD++/7oZU/+MB3hxFbXr7c93Zd22BbubmHJobYcn2TBtISST4lAqmXmf+Fn58PRQlLGL3KSti+3SeIjz+ue1q71s9LSnwP17XJzDw8OcSGH4j1TB0/1EBtyx07RnfANpH6KBFIi8nIqC4aaijnfLFTomTxySeHb9uyxVd8x4ZPqKho+HdlZfmEEBsZsrapKcfk5Pjir5yc6ik7W8lH2gYlAgmVWfWYNAUFjT9///7q0StjQwzXXI+Nt7Nnz6FT/LbSUvjww8T7miMrqzpR1DdlZx86KFwyp/R0FblJtaQmAjM7B7gXSAd+55z7WY39Fuw/D9gNXOmcW57MmKR9ycqqLjJKBud83061JZDYtG+fb5obm+LX9+w5dDl+344dh+6LHxguNiWDmf/bZWT4pJBoqmtfQ49p7v7W+I7GxBAbkC8trXo5NrVlSUsEZpYO/Ab4NFAM/NPM5jnn3o477Fzg2GAaA9wfzEVSgln1L/Yjjmj973fO173ED/vcUtO+ff6zDxyofWro/tjw0409P9ExtTU4SHXxySFRwqhtW2PO+frX4brrWj72ZD4RjAbWO+c2AJjZI8CFQHwiuBD4o/Nvtb1mZl3NrLdz7oMkxiXSZphVD+3csWPY0bSO2LDYjU1GLZHQ6tsfiy02j19u6LamnBObH3lkcv7myUwEfYEtcevFHP5rP9ExfYFDEoGZTQWmAhx11FEtHqiIpA6z6iIZaR3JbNOQqNSsZn8WDTkG59xM51yRc64oPz+/RYITEREvmYmgGOgXt14AbG3CMSIikkTJTAT/BI41swFmlgVcAsyrccw84HLzTgZKVT8gItK6klZH4JyrNLNrgGfwzUcfcM6tMrOrg/0zgAX4pqPr8c1Hv5KseEREJLGkvkfgnFuAv9nHb5sRt+yAbyczBhERqZtegBcRiTglAhGRiFMiEBGJuDY3VKWZbQc2N/H0HsBHLRhOW6BrjgZdczQ055qPds4lfBGrzSWC5jCzpbWN2dle6ZqjQdccDcm6ZhUNiYhEnBKBiEjERS0RzAw7gBDomqNB1xwNSbnmSNURiIjI4aL2RCAiIjUoEYiIRFxkEoGZnWNma81svZndEnY8TWVm/czsRTNbbWarzOy7wfZuZvacma0L5kfEnXNrcN1rzezsuO0nmtlbwb7pwRjSKcvM0s3sX2b2ZLDerq85GLHvr2a2Jvj3HhuBa74u+O96pZk9bGY57e2azewBM9tmZivjtrXYNZpZtpk9Gmx/3cz61xuUc67dT/jeT98FBgJZwBvAkLDjauK19AZGBct5wDvAEODnwC3B9luA/w6WhwTXmw0MCP4O6cG+JcBY/ABBTwHnhn199Vz79cD/AU8G6+36moE/AFcFy1lA1/Z8zfjRCTcCHYL1vwBXtrdrBsYDo4CVcdta7BqBbwEzguVLgEfrjSnsP0or/eHHAs/Erd8K3Bp2XC10bY8DnwbWAr2Dbb2BtYmuFd8t+NjgmDVx278I/Dbs66njOguA54EzqU4E7faagc7BTdFqbG/P1xwburYbvmfkJ4Gz2uM1A/1rJIIWu8bYMcFyBv5NZKsrnqgUDdU2NnKbFjzyjQReB3q6YFCfYB4b5rq2a+8bLNfcnqruAW4CquK2tedrHghsBx4MisN+Z2a5tONrds69D/wSeA8/bnmpc+5Z2vE1x2nJazx4jnOuEigFutf15VFJBA0aG7ktMbNOwN+Aa51zO+s6NME2V8f2lGNm5wPbnHPLGnpKgm1t6prxv+RGAfc750YCu/BFBrVp89cclItfiC8C6QPkmtmldZ2SYFubuuYGaMo1Nvr6o5II2tXYyGaWiU8CDznnZgeb/21mvYP9vYFtwfbarr04WK65PRWdAlxgZpuAR4AzzezPtO9rLgaKnXOvB+t/xSeG9nzN/wFsdM5td85VALOBcbTva45pyWs8eI6ZZQBdgI/r+vKoJIKGjJ/cJgQtA34PrHbO/Spu1zzgimD5CnzdQWz7JUFLggHAscCS4PGzzMxODj7z8rhzUopz7lbnXIFzrj/+3+4F59yltO9r/hDYYmbHBZsmAm/Tjq8ZXyR0spl1DGKdCKymfV9zTEteY/xnXYz//6XuJ6KwK01asXLmPHwLm3eB28KOpxnXcSr+Me9NYEUwnYcvA3weWBfMu8Wdc1tw3WuJaz0BFAErg333UU+FUipMwASqK4vb9TUDhcDS4N96LnBEBK75v4A1Qbx/wreWaVfXDDyMrwOpwP96/1pLXiOQAzyGHwt+CTCwvpjUxYSISMRFpWhIRERqoUQgIhJxSgQiIhGnRCAiEnFKBCIiEadEIJFjZi+ZWdIHPTezaUGvoQ8l+7tqfO+dZnZDa36ntG0ZYQcg0paYWYbz/bc0xLfw7b43JjMmkebSE4GkJDPrH/ya/t+gf/pnzaxDsO/gL3oz6xF0PYGZXWlmc83sCTPbaGbXmNn1Qadtr5lZt7ivuNTMXgn6vR8dnJ8b9BX/z+CcC+M+9zEzewJ4NkGs1wefs9LMrg22zcB3HDfPzK6rcXy6mf0i+J43zewbwfYJZrbIzOaY2dtmNsPM0oJ9Xwz6nl9pZv8d91nnmNlyM3vDzJ6P+5ohwd9pg5lNi7u++cGxK83sC834J5L2JOy37DRpSjThu+mtBAqD9b8AlwbLLwFFwXIPYFOwfCX+bco8IB/f6+LVwb678R30xc7/32B5PEF3wMBP4r6jK/5N9Nzgc4uJe9szLs4TgbeC4zoBq4CRwb5NQI8E50wFbg+Ws/FvDw/AvzW9F59A0oHn8F0E9MF3v5CPf4p/AbgoWN8CDAg+q1swvxN4JfjsHkAJkAl8NnbdwXFdwv531pQak4qGJJVtdM6tCJaX4ZNDfV50zpXh+2EpBZ4Itr8FDI877mEA59wiM+tsZl3xfd9fEFe+ngMcFSw/55xL1HHXqcAc59wuADObDZwG/KuOGM8ChpvZxcF6F3wfMvvx/chsCD7r4eDzK4CXnHPbg+0P4RPYAWCRC4qeasQ33zm3D9hnZtuAnsHf4JfBE8WTzrnFdcQoEaJEIKlsX9zyAaBDsFxJdbFmTh3nVMWtV3Hof+81+1aJde37Wefc2vgdZjYG3w10Ik0ZAtGA7zjnnqnxPRPqiKu2z6mtj5iaf7sM59w7ZnYivm+qn5rZs865uxoZu7RDqiOQtmgTvkgGfNFJU3wBwMxOxQ+AUoof2ek7QW+OmNnIBnzOIuCioMfMXOAzQH2/tJ8Bvmm+O3HMbHBwLsBo873kpgUxvowfeOj0oD4kHT8a1d+BV4PtA4LP6Vbzi+KZWR9gt3Puz/gBYEY14PokAvREIG3RL4G/mNll+PLypvjEzF7BDwn51WDbD/Ejob0ZJINNwPl1fYhzbrmZzcL38gjwO+dcXcVCAL/DF3MtD75nO77MH/zN/WfAMHySmeOcqzKzW4EX8U8BC5xzjwOY2VRgdpA4tuGHLa3NMOAXZlaFL276Zj1xSkSo91GRFBEUDd3gnKsz+Yi0NBUNiYhEnJ4IREQiTk8EIiIRp0QgIhJxSgQiIhGnRCAiEnFKBCIiEff/ExwhHVfQ0zQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(0, no_epochs), train_losses, color='blue')\n",
    "plt.plot(range(0, no_epochs), test_losses, color='red')\n",
    "plt.legend(['Train Loss', \"Test Loss\"], loc='upper right')\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN8btFSP3yU2"
   },
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check the model accuracy on the test data. For this we predict on the test data, identify the class with the highest score and compare it to the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsmVfo49Kytp",
    "outputId": "73bdda50-20d6-41e3-bb45-ce40c114f6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy is 91.38888888888889%\n"
     ]
    }
   ],
   "source": [
    "net.eval() # set network to evaluation mode\n",
    "y_pred = net(test_x)\n",
    "_, predicted = torch.max(y_pred.data, 1)\n",
    "correct = (predicted == test_y).sum().item()\n",
    "print(f\"Accuarcy is {100. * correct / len(test_x)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Our accuracy is not so good on the test data. Try the following to improve the model:\n",
    "    - Increase the hidden layer size to 10 neurons, train the model and compare the accuracy on the test data.\n",
    "    - Add a second hidden layer with 5 neurons, train the model and compare the accuracy on the test data.\n",
    "2. Check if you can decrease the training loss even further if you train for more epochs. However, this can easily result in overfitting. To check that, calculate the accuracy on the test data already during training after each epoch. Show the plot the results as a second plot similiar to the one above. (Note: Normally we need to do this check on seperate validation data, not on our test data).\n",
    "3. Take the titanic data set and try to train a neural network on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions:\n",
    "1. Accuracy can be improved to 81%. See code changes above.\n",
    "2. We can see that test loss does not get better after 2000 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/titanic.csv\")\n",
    "df_selection = df[[\"Survived\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "df_selection = df_selection.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_selection.drop(columns = [\"Survived\"]).values\n",
    "df_y = df_selection[\"Survived\"].values\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_X, df_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is important above is that we transform the Pandas objects into numpy nd-arrays by applying the `.values`, because PyTorch does not really like to create tensors out of Pandas DataFrames or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_x).float().to(device)\n",
    "test_x = torch.Tensor(test_x).float().to(device)\n",
    "train_y = torch.Tensor(train_y).long().to(device)\n",
    "test_y = torch.Tensor(test_y).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TitanicNet, self).__init__()\n",
    "    self.hidden = nn.Linear(5, 10)\n",
    "    self.output = nn.Linear(10, 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = F.relu(self.hidden(x))\n",
    "    z = self.output(z)  # no softmax. see CrossEntropyLoss() \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training \n",
      "Loss in epoch 0 is 1.4843826293945312\n",
      "Loss in epoch 100 is 0.5951008200645447\n",
      "Loss in epoch 200 is 0.5931857228279114\n",
      "Loss in epoch 300 is 0.5906314253807068\n",
      "Loss in epoch 400 is 0.5895885229110718\n",
      "Loss in epoch 500 is 0.5888893604278564\n",
      "Loss in epoch 600 is 0.5881949067115784\n",
      "Loss in epoch 700 is 0.5873887538909912\n",
      "Loss in epoch 800 is 0.586796224117279\n",
      "Loss in epoch 900 is 0.5856370329856873\n",
      "Loss in epoch 1000 is 0.5846630930900574\n",
      "Loss in epoch 1100 is 0.585145890712738\n",
      "Loss in epoch 1200 is 0.583357572555542\n",
      "Loss in epoch 1300 is 0.5823001265525818\n",
      "Loss in epoch 1400 is 0.581509530544281\n",
      "Loss in epoch 1500 is 0.579550564289093\n",
      "Loss in epoch 1600 is 0.5784775018692017\n",
      "Loss in epoch 1700 is 0.577573835849762\n",
      "Loss in epoch 1800 is 0.5784035921096802\n",
      "Loss in epoch 1900 is 0.5760794281959534\n",
      "Loss in epoch 2000 is 0.576495885848999\n",
      "Loss in epoch 2100 is 0.575948178768158\n",
      "Loss in epoch 2200 is 0.5760431885719299\n",
      "Loss in epoch 2300 is 0.5781943798065186\n",
      "Loss in epoch 2400 is 0.5762698650360107\n",
      "Loss in epoch 2500 is 0.5756537914276123\n",
      "Loss in epoch 2600 is 0.5770686864852905\n",
      "Loss in epoch 2700 is 0.5739690065383911\n",
      "Loss in epoch 2800 is 0.5738748908042908\n",
      "Loss in epoch 2900 is 0.5759969353675842\n",
      "Loss in epoch 3000 is 0.5732998847961426\n",
      "Loss in epoch 3100 is 0.572851836681366\n",
      "Loss in epoch 3200 is 0.5724315047264099\n",
      "Loss in epoch 3300 is 0.5718771815299988\n",
      "Loss in epoch 3400 is 0.5713542103767395\n",
      "Loss in epoch 3500 is 0.5703055262565613\n",
      "Loss in epoch 3600 is 0.568458080291748\n",
      "Loss in epoch 3700 is 0.5714085698127747\n",
      "Loss in epoch 3800 is 0.5705298185348511\n",
      "Loss in epoch 3900 is 0.5680009722709656\n",
      "Loss in epoch 4000 is 0.5678946375846863\n",
      "Loss in epoch 4100 is 0.5667819976806641\n",
      "Loss in epoch 4200 is 0.5669754147529602\n",
      "Loss in epoch 4300 is 0.5668917894363403\n",
      "Loss in epoch 4400 is 0.5665627121925354\n",
      "Loss in epoch 4500 is 0.565764307975769\n",
      "Loss in epoch 4600 is 0.565635085105896\n",
      "Loss in epoch 4700 is 0.5652162432670593\n",
      "Loss in epoch 4800 is 0.5650262832641602\n",
      "Loss in epoch 4900 is 0.564363420009613\n",
      "Loss in epoch 5000 is 0.5641539096832275\n",
      "Loss in epoch 5100 is 0.5634335279464722\n",
      "Loss in epoch 5200 is 0.5635901093482971\n",
      "Loss in epoch 5300 is 0.5634828805923462\n",
      "Loss in epoch 5400 is 0.56232750415802\n",
      "Loss in epoch 5500 is 0.5617094039916992\n",
      "Loss in epoch 5600 is 0.5618562698364258\n",
      "Loss in epoch 5700 is 0.5614988207817078\n",
      "Loss in epoch 5800 is 0.5609490871429443\n",
      "Loss in epoch 5900 is 0.560783863067627\n",
      "Loss in epoch 6000 is 0.5608983635902405\n",
      "Loss in epoch 6100 is 0.5600097179412842\n",
      "Loss in epoch 6200 is 0.5602139234542847\n",
      "Loss in epoch 6300 is 0.5599461197853088\n",
      "Loss in epoch 6400 is 0.5597438216209412\n",
      "Loss in epoch 6500 is 0.5594180822372437\n",
      "Loss in epoch 6600 is 0.5592231154441833\n",
      "Loss in epoch 6700 is 0.5590662360191345\n",
      "Loss in epoch 6800 is 0.5589684844017029\n",
      "Loss in epoch 6900 is 0.5586779117584229\n",
      "Loss in epoch 7000 is 0.5585594773292542\n",
      "Loss in epoch 7100 is 0.5586243271827698\n",
      "Loss in epoch 7200 is 0.5582560300827026\n",
      "Loss in epoch 7300 is 0.558019757270813\n",
      "Loss in epoch 7400 is 0.5576490163803101\n",
      "Loss in epoch 7500 is 0.5575821995735168\n",
      "Loss in epoch 7600 is 0.5579314231872559\n",
      "Loss in epoch 7700 is 0.5577892661094666\n",
      "Loss in epoch 7800 is 0.5578325986862183\n",
      "Loss in epoch 7900 is 0.5577590465545654\n",
      "Loss in epoch 8000 is 0.5570016503334045\n",
      "Loss in epoch 8100 is 0.5574284791946411\n",
      "Loss in epoch 8200 is 0.5566803812980652\n",
      "Loss in epoch 8300 is 0.5571357607841492\n",
      "Loss in epoch 8400 is 0.5569122433662415\n",
      "Loss in epoch 8500 is 0.556452214717865\n",
      "Loss in epoch 8600 is 0.5561842918395996\n",
      "Loss in epoch 8700 is 0.5563248991966248\n",
      "Loss in epoch 8800 is 0.5558533668518066\n",
      "Loss in epoch 8900 is 0.5563120245933533\n",
      "Loss in epoch 9000 is 0.5560191869735718\n",
      "Loss in epoch 9100 is 0.5558522939682007\n",
      "Loss in epoch 9200 is 0.5553396344184875\n",
      "Loss in epoch 9300 is 0.5550900101661682\n",
      "Loss in epoch 9400 is 0.5551429986953735\n",
      "Loss in epoch 9500 is 0.5549402236938477\n",
      "Loss in epoch 9600 is 0.5548370480537415\n",
      "Loss in epoch 9700 is 0.5546244382858276\n",
      "Loss in epoch 9800 is 0.5548811554908752\n",
      "Loss in epoch 9900 is 0.5548372864723206\n",
      "Done training \n"
     ]
    }
   ],
   "source": [
    "net = TitanicNet().to(device)\n",
    "net.train()\n",
    "\n",
    "# define the parameters for training\n",
    "no_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "loss_func = nn.CrossEntropyLoss()  # applies softmax() internally\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nStarting training \")\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(0, no_epochs):\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  output = net(train_x)\n",
    "\n",
    "  loss = loss_func(output, train_y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  y_test = net(test_x)\n",
    "  loss_test = loss_func(y_test, test_y)\n",
    "\n",
    "  train_losses.append(loss.item())\n",
    "  test_losses.append(loss_test.item())\n",
    "  \n",
    "  if epoch % 100 == 0:\n",
    "    print(f\"Loss in epoch {epoch} is {loss.item()}\")\n",
    "\n",
    "print(\"Done training \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgVUlEQVR4nO3deXxV1b338c+PJCYyCUKciBS4F62IEDSVgsqgrXPlOrVaUWnr5dFeRevLCW1tq/W52vZxoPZKrRdp1UdtEVCLLRWVQutUsKigTDJIihcClohQhpDf/WPtwEk8GcnhJFnf9+t1Xtlnj2uFcL5nr7322ubuiIhIvNpluwAiIpJdCgIRkcgpCEREIqcgEBGJnIJARCRyudkuQGN1797de/Xqle1iiIi0KvPnz9/g7oXplrW6IOjVqxfz5s3LdjFERFoVM1td2zI1DYmIRE5BICISOQWBiEjkWt01AhFpW3bu3ElpaSnbtm3LdlHahIKCAoqKisjLy2vwNgoCEcmq0tJSOnXqRK9evTCzbBenVXN3Nm7cSGlpKb17927wdmoaEpGs2rZtG926dVMINAMzo1u3bo0+u1IQiEjWKQSaT1N+l9EEwaJFcPvtsH59tksiItKyRBME770Hd94JZWXZLomItCQbN26kuLiY4uJiDjnkEHr06LH7/Y4dO+rcdt68eYwbN65Rx+vVqxcbNmzYmyI3O10sFpGodevWjQULFgDwgx/8gI4dO3LDDTfsXl5RUUFubvqPypKSEkpKSvZFMTMqmjMCEZGGGjNmDNdffz0jR47k5ptv5s0332To0KEMGjSIoUOHsmTJEgBmz57N2WefDYQQ+eY3v8mIESPo06cPEyZMaPDxVq9ezSmnnMKAAQM45ZRT+PDDDwH47W9/S//+/Rk4cCDDhg0DYNGiRRx//PEUFxczYMAAli1bttf11RmBiLQY110HyZfzZlNcDPff3/jtli5dyqxZs8jJyeGTTz5hzpw55ObmMmvWLG699VaeeeaZz2yzePFiXnnlFTZv3syRRx7JVVdd1aD+/FdffTWXXXYZl19+OZMmTWLcuHFMnz6dO+64g5kzZ9KjRw82bdoEwMSJE7n22mu55JJL2LFjB7t27Wp85WpQEIiIpHHhhReSk5MDQHl5OZdffjnLli3DzNi5c2fabc466yzy8/PJz8/noIMOYt26dRQVFdV7rNdee42pU6cCcOmll3LTTTcBcMIJJzBmzBi++tWvct555wEwZMgQ7rrrLkpLSznvvPPo27fvXtc1uiBwz3YJRKQ2TfnmnikdOnTYPf29732PkSNHMm3aNFatWsWIESPSbpOfn797Oicnh4qKiiYdu6oL6MSJE3njjTeYMWMGxcXFLFiwgK9//esMHjyYGTNmcNppp/HII49w8sknN+k4VaK5RqBuyiLSVOXl5fTo0QOAyZMnN/v+hw4dylNPPQXAE088wYknngjABx98wODBg7njjjvo3r07a9asYcWKFfTp04dx48Zxzjnn8M477+z18aMJAhGRprrpppsYP348J5xwQrO0yQ8YMICioiKKioq4/vrrmTBhAo8++igDBgzgscce44EHHgDgxhtv5JhjjqF///4MGzaMgQMH8vTTT9O/f3+Ki4tZvHgxl1122V6Xx7yVtZWUlJR4Ux5MM2UKXHghvPsu9O+fgYKJSJO8//77HHXUUdkuRpuS7ndqZvPdPW1fV50RiIhETkEgIhK56IKglbWEiYhkXDRBoF5DIiLpRRMEIiKSnoJARCRyGQsCM5tkZuvNbGE9633BzHaZ2QWZKouISG32ZhhqCAPPvfrqq2mXTZ48mauvvrq5i9zsMjnExGTgQeDXta1gZjnAPcDMDJZDRKRW9Q1DXZ/Zs2fTsWNHhg4dmqESZl7GzgjcfQ7wcT2rXQM8A+yz54ap15CI1Gf+/PkMHz6c4447jtNOO42PPvoIgAkTJtCvXz8GDBjARRddxKpVq5g4cSL33XcfxcXFzJ07t0H7v/fee+nfvz/9+/fn/mSApS1btnDWWWcxcOBA+vfvz9NPPw3ALbfcsvuYjQmoxsjaoHNm1gM4FzgZ+EI9644FxgL07Nmzicdr0mYisi+1gHGo3Z1rrrmGZ599lsLCQp5++mluu+02Jk2axN13383KlSvJz89n06ZNdOnShSuvvLJRZxHz58/n0Ucf5Y033sDdGTx4MMOHD2fFihUcdthhzJgxAwjjG3388cdMmzaNxYsXY2a7h6Jubtm8WHw/cLO71ztwh7s/7O4l7l5SWFiY+ZKJSLS2b9/OwoUL+fKXv0xxcTE/+tGPKC0tBcIYQZdccgmPP/54rU8tq8+f//xnzj33XDp06EDHjh0577zzmDt3LscccwyzZs3i5ptvZu7cuRxwwAF07tyZgoICrrjiCqZOnUr79u2bs6q7ZXMY6hLgqWS41e7AmWZW4e7Ts1gmEcmmFjAOtbtz9NFH89prr31m2YwZM5gzZw7PPfccd955J4sWLWrS/tM54ogjmD9/Pi+88ALjx4/n1FNP5fbbb+fNN9/kpZde4qmnnuLBBx/k5ZdfbvQx65O1MwJ37+3uvdy9FzAF+LZCQESyLT8/n7Kyst1BsHPnThYtWkRlZSVr1qxh5MiR/PjHP2bTpk18+umndOrUic2bNzd4/8OGDWP69Ols3bqVLVu2MG3aNE466STWrl1L+/btGT16NDfccANvvfUWn376KeXl5Zx55pncf//9uy9qN7eMnRGY2ZPACKC7mZUC3wfyANx9YqaOWx9dLBaRurRr144pU6Ywbtw4ysvLqaio4LrrruOII45g9OjRlJeX4+585zvfoUuXLnzlK1/hggsu4Nlnn+VnP/sZJ510UrX9TZ48menTp+9+//rrrzNmzBiOP/54AK644goGDRrEzJkzufHGG2nXrh15eXk89NBDbN68mVGjRrFt2zbcnfvuuy8jdY5mGOpp0+C888J1qIEDm79cItI0Goa6+WkYahERaRQFgYhI5BQEIpJ1ra2JuiVryu9SQSAiWVVQUMDGjRsVBs3A3dm4cSMFBQWN2i6b9xFkhf7WRFqWoqIiSktLKSsry3ZR2oSCggKKiooatU00QaAhJkRapry8PHr37p3tYkRNTUMiIpFTEIiIRE5BICISOQWBiEjkogsC9RoSEakumiBQryERkfSiCQIREUlPQSAiEjkFgYhI5BQEIiKRiy4I1GtIRKS6aIJAvYZERNKLJghERCQ9BYGISOQUBCIikVMQiIhELrogUK8hEZHqogkC9RoSEUkvmiAQEZH0FAQiIpFTEIiIRE5BICISueiCQL2GRESqiyYI1GtIRCS9aIJARETSUxCIiEROQSAiErmMBYGZTTKz9Wa2sJbll5jZO8nrVTMbmKmyiIhI7TJ5RjAZOL2O5SuB4e4+ALgTeDiDZdlNvYZERKrLzdSO3X2OmfWqY/mrKW9fB4oyVRZQryERkdq0lGsE3wJ+X9tCMxtrZvPMbF5ZWdk+LJaISNuX9SAws5GEILi5tnXc/WF3L3H3ksLCwn1XOBGRCGSsaaghzGwA8AhwhrtvzGZZRERilbUzAjPrCUwFLnX3pdkqh4hI7DJ2RmBmTwIjgO5mVgp8H8gDcPeJwO1AN+C/LFzJrXD3kkyVp4p6DYmIVJfJXkMX17P8CuCKTB2/JvUaEhFJL+sXi0VEJLsUBCIikVMQiIhELrog0MViEZHqogkCXSwWEUkvmiAQEZH0FAQiIpFTEIiIRE5BICISueiCQL2GRESqiyYI1GtIRCS9aIJARETSUxCIiEROQSAiEjkFgYhI5KILAvUaEhGpLpogUK8hEZH0ogkCERFJT0EgIhI5BYGISOQUBCIikYsuCNRrSESkumiCQL2GRETSiyYIREQkPQWBiEjkFAQiIpFTEIiIRK5BQWBm15pZZwv+28zeMrNTM124TFCvIRGR6hp6RvBNd/8EOBUoBL4B3J2xUmWAeg2JiKTX0CCo+hg9E3jU3d9OmSciIq1YQ4Ngvpn9kRAEM82sE1CZuWKJiMi+ktvA9b4FFAMr3H2rmR1IaB4SEZFWrqFnBEOAJe6+ycxGA98FyjNXLBER2VcaGgQPAVvNbCBwE7Aa+HVdG5jZJDNbb2YLa1luZjbBzJab2TtmdmyjSt5E6jUkIlJdQ4Ogwt0dGAU84O4PAJ3q2WYycHody88A+iavsYSwyRj1GhIRSa+hQbDZzMYDlwIzzCwHyKtrA3efA3xcxyqjgF978DrQxcwObWB5RESkmTQ0CL4GbCfcT/A/QA/gJ3t57B7AmpT3pck8ERHZhxoUBMmH/xPAAWZ2NrDN3eu8RtAA6Rpr0rbgm9lYM5tnZvPKysr28rAiIpKqoUNMfBV4E7gQ+CrwhpldsJfHLgUOT3lfBKxNt6K7P+zuJe5eUlhYuJeHFRGRVA29j+A24Avuvh7AzAqBWcCUvTj2c8DVZvYUMBgod/eP9mJ/DaJeQyIi1TU0CNpVhUBiI/WcTZjZk8AIoLuZlQLfJ7nA7O4TgRcIdyovB7aS4RvU1GtIRCS9hgbBH8xsJvBk8v5rhA/yWrn7xfUsd+A/Gnh8ERHJkAYFgbvfaGbnAycQLvI+7O7TMloyERHZJxp6RoC7PwM8k8GyiIhIFtQZBGa2mfRdOo3QutM5I6XKIF0sFhGprs4gcPf6hpFoNXSxWEQkPT2zWEQkcgoCEZHIKQhERCKnIBARiVx0QaBeQyIi1UUTBDnbt3IH38N2bM92UUREWpRoguBzT97N9/gRhz3/i2wXRUSkRYkmCNpt2wqA7dQZgYhIqmiCYA/dWSYikiqiINBVYhGRdCIKAhERSSeaIFCDkIhIetEEQdUNBK7R50REqoknCEREJK0Ig0BnBCIiqSIMAhERSRVREKj7qIhIOtEEQVWDkKtpSESkmmiCQERE0osnCDT+tIhIWvEEQRXdRyAiUk1EQaAzAhGRdCIKgkBxICJSXTRBoAYhEZH0ogmCPRQJIiKp4gkC9RoSEUkrniCool5DIiLVxBcEIiJSTTxBUPU8giwXQ0SkpYkmCPa0CKlpSEQkVUaDwMxON7MlZrbczG5Js/wAM3vezN42s0Vm9o1MlkdERD4rY0FgZjnAz4EzgH7AxWbWr8Zq/wG85+4DgRHA/zOz/TJSIPUaEhFJK5NnBMcDy919hbvvAJ4CRtVYx4FOZmZAR+BjoCKDZVKvIRGRGjIZBD2ANSnvS5N5qR4EjgLWAu8C17p7Zc0dmdlYM5tnZvPKysqaVJjthUUAVLTv3KTtRUTaqkwGQbqv3jXbZ04DFgCHAcXAg2b2mU9qd3/Y3UvcvaSwsLBJhdncfwgA27oXNWl7EZG2KpNBUAocnvK+iPDNP9U3gKkeLAdWAp/PSGnUJCQiklYmg+CvQF8z651cAL4IeK7GOh8CpwCY2cHAkcCKDJZJRERqyM3Ujt29wsyuBmYCOcAkd19kZlcmyycCdwKTzexdQlPSze6+IVNlEhGRz8pYEAC4+wvACzXmTUyZXgucmskypCnUPj2ciEhLF82dxbpGICKSXjRBoBwQEUkvmiAQEZH04gsCXSMQEakmmiBwjToqIpJWNEEgIiLpRRcEahkSEakumiDY3WtISSAiUk00QaD+oyIi6cUTBCIikpaCQEQkctEFgX3mkQgiInGLJwiSawS6ViwiUl1GRx9tUXStuGG2b4ctW2DFCvjXf4Vf/Qq++MUw709/gtGjoaICevSAf/4TfvELOPpoOP98WLoU5s6FK66ovs9f/hJGjYKNG2HbtnCMhQth0CDo2hWWL4eHH4YvfQnWrg3HHT4cDj4YZs+Gk0+GvLys/DpEYhBPEEh1W7bABRfAH/7QuO3uuKPxx/r3fw+v+kyZUvuy9u1DAB15JHTrBiNGhEB5/XW4+2546aUQXs89B+vXw6uvwpAhjS8rQFlZCJ7Vq2HXLjj22KbtR6SViC8I1DYUXHRR40Mgm7ZuDT/ffTf8nD17z7LBgz+7/tChTf+3Puig6u/1NyPZ9MAD4cvO+efDffdl5Ow4oiCIoG3IHdqlXPaprIQlS8I33GHDsleubGmue0fq28/o0aFZrLIynEUUF8Ott8JRR4UzmfXrw8/KSujcGfbfP5zJDBgQzswKCyG3lf5XrBmSlZVhXkVF+MDKyQnzduzYs87WrZCfH5atWRPq/o9/QGlpaDrs2TOcib3wAvTpE6YPOACWLQt/34WF4W9650445BDo1Ak2bYLy8vDeHT78ED79FLp0CWeO27eH6TVrQtCvXBn2U9VU+S//Er5kHHooHHYYdO8OH38cypibG17t20OHDqFuXbuG5tGOHcMZal5e+Ld0D+Xq2jVsu2VLWKfq99Sulsuy27eH30lNFRVw3XVh+uc/h7/8Bf72t737N0ujlf71yW7l5eEPPJ3a/uikeT3+ePX3L74YXiLNbcGCjOxWnxStyerV4RTRbM+rthAQEWmgaM4Iqs7ucz/dlNVy1GvtWnjnndCE8Pzz4YNfRCSDogmCTu++CkDx3RfBf34tewW56y444wzo1y/02pk3D9aty155RCR60QRB/tqV2Tv43LnwxBOhzz3Ad7+bvbKIiNQQTRBUc+ON8JOfNG6bbdv29IJI5/33w7d8EZFWJp6LxaldAH/608Ztu2lT6PKXm1v9Qm3qSyEgIq1UNEHgNfuCd+y4Z/rjj2HChNo/5Lt23beFFRHZh6JpGrKaN75s2aKH1YiIENEZARp+WkQkrWiCYFcnNe+IiKQTTRD8/fJbs10EEZEWKZog8IL9MZzfv+BhAKj6XhUVYeCqc8/NdtFFRDIqmiCoui5cWdnADXJy4PDDYerUEAyVlbBqVRj06YYbMlRKEZE6LF+ekd1G02uoagjvioom7sAMPve58Bo4sO4b0qrOKj75BD74IATIlClhRMqNG5t2/Nzc8EfQs+eeVKvqCWUWhrGtqAhdYefNC8P3vvgiHHhgGAJ4164wbO6OHXDEEaFcVeMabdoUhkUuLQ37GzgQ3n67aeUUqVI1XPSgQeFBQps3hy9URx4JffuGv+nCwjDdvn342ywoCPOrRs41C3+77dqpl18GRRMEVcO979y5Dw6WOjLocceF1/nnZ+Y4VfLzw6tDh3AmA+EDvTbFxc1fnpile3hNamCb7fmZOk/22H//9PNru5tfmk1Gm4bM7HQzW2Jmy83sllrWGWFmC8xskZn9KVNl2eszApG6pLsRMXVZ6s+a0yJZlrEgMLMc4OfAGUA/4GIz61djnS7AfwHnuPvRwIWZKs+uXeHnb36TqSOIiLROmTwjOB5Y7u4r3H0H8BQwqsY6XwemuvuHAO6+PlOFqWoSmjYtPK1ORESCTF4j6AGkfuSWAjWfMn4EkGdms4FOwAPu/uuaOzKzscBYgJ49ezapMKlN4j17ws03h3HiiorCtaqqZnURkdhkMgjSNYLWvKKWCxwHnALsD7xmZq+7+9JqG7k/DDwMUFJS0uSxIjZvDs+5BrjnnurL+vQJnRvy8sKzq2fNCh1q8vJg+PDwHuDZZ+G009I/Z1pEpDXKZBCUAqnfs4uAtWnW2eDuW4AtZjYHGAgsJQM6dtzTuWPLlnC/2N//Dm++GT7o586F9TUap3bu3BMCAKNqNm41wsiR8MorYfrll+Hoo6F7dz1jXkSyK5MfQX8F+ppZbzPbD7gIeK7GOs8CJ5lZrpm1JzQdvZ/BMu3WoQMcdRR86Utw663hg3ndutDNed268MiCqrOH5lIVAgAnnwwHHxx6xtU2+nXq6557Qkil66WYqrJSPaNEpHHM6/tk2Zudm50J3A/kAJPc/S4zuxLA3Scm69wIfAOoBB5x9/vr2mdJSYnPmzcvY2VujMrKcP/W7bfDQw9luzTZNWYM/POfsGgRLFwY5h1+OPTvD1ddFa7HdOgQ7ufo0CEsr63buIg0PzOb7+4laZdlMggyoSUFQWOsWROefTNlSrjRWPZe374wZAjccksImLKycO1m+nS4+upwxiUigYKglfnkE/jhD+Hee7NdEqkyZgwccgh84QuhA8HnPx+u7xQUwH77heY7XeuRlkxB0Ea5h4vZy5eHaxrPPw8bNmS7VJIt7dqF5soDDwwjmmzYEJrnunaFgw7ac12sqCh0nDDb04HCLGyr0RzaLgWB1KuiArZuDe38mzeHtv5HH4Vly+C997JdOpGWo3v30N28Xz/o3BmGDQvjOX7ySXjfsWMI44IC+PRTOPTQELBVQbtr155OIpB+KKpUjz0GY8eGs9L77gv7bQoFgbRIqY9+2LEjTG/cCCtXwvvvh15Wc+eGXlwiEjT1I1tBINLMqh5RAaFJZt06+OijcF+Ke2iu27wZ/vKX0DQzY0ZonikrC/NFmioTQRDNMNQizcmsenv6IYeE16BB2SvTvpb6gVTVtAGh6WPnzhCUO3bA6tWhyfGjj0IQVlaGGzpzckIPug0bQrOke3gkxtKloell2zZYsgSOPTbc0/OnjI1N3Hp8//uZ2a+CQESapGZ7dtX73Nw9z//o0CGcEUnLpg5vIiKRUxCIiEROQSAiEjkFgYhI5BQEIiKRUxCIiEROQSAiEjkFgYhI5FrdEBNmVgasbuLm3YHYxudUneOgOsdhb+r8OXcvTLeg1QXB3jCzebWNtdFWqc5xUJ3jkKk6q2lIRCRyCgIRkcjFFgQPZ7sAWaA6x0F1jkNG6hzVNQIREfms2M4IRESkBgWBiEjkogkCMzvdzJaY2XIzuyXb5WkqMzvczF4xs/fNbJGZXZvMP9DMXjSzZcnPrinbjE/qvcTMTkuZf5yZvZssm2CW7tHZLYeZ5ZjZ38zsd8n7Nl1nM+tiZlPMbHHy7z0kgjp/J/m7XmhmT5pZQVurs5lNMrP1ZrYwZV6z1dHM8s3s6WT+G2bWq95CuXubfwE5wAdAH2A/4G2gX7bL1cS6HAocm0x3ApYC/YAfA7ck828B7kmm+yX1zQd6J7+HnGTZm8AQwIDfA2dku3711P164P8Dv0vet+k6A78Crkim9wO6tOU6Az2AlcD+yfvfAGPaWp2BYcCxwMKUec1WR+DbwMRk+iLg6XrLlO1fyj76xQ8BZqa8Hw+Mz3a5mqluzwJfBpYAhybzDgWWpKsrMDP5fRwKLE6ZfzHwi2zXp456FgEvASezJwjabJ2BzsmHotWY35br3ANYAxxIeIzu74BT22KdgV41gqDZ6li1TjKdS7gT2eoqTyxNQ1V/YFVKk3mtWnLKNwh4AzjY3T8CSH4elKxWW917JNM157dU9wM3AZUp89pynfsAZcCjSXPYI2bWgTZcZ3f/O/BT4EPgI6Dc3f9IG65ziuas4+5t3L0CKAe61XXwWIIgXftgq+43a2YdgWeA69z9k7pWTTPP65jf4pjZ2cB6d5/f0E3SzGtVdSZ8kzsWeMjdBwFbCE0GtWn1dU7axUcRmkAOAzqY2ei6Nkkzr1XVuQGaUsdG1z+WICgFDk95XwSszVJZ9pqZ5RFC4Al3n5rMXmdmhybLDwXWJ/Nrq3tpMl1zfkt0AnCOma0CngJONrPHadt1LgVK3f2N5P0UQjC05Tp/CVjp7mXuvhOYCgylbde5SnPWcfc2ZpYLHAB8XNfBYwmCvwJ9zay3me1HuIDyXJbL1CRJz4D/Bt5393tTFj0HXJ5MX064dlA1/6KkJ0FvoC/wZnL6udnMvpjs87KUbVoUdx/v7kXu3ovwb/eyu4+mbdf5f4A1ZnZkMusU4D3acJ0JTUJfNLP2SVlPAd6nbde5SnPWMXVfFxD+v9R9RpTtiyb78OLMmYQeNh8At2W7PHtRjxMJp3nvAAuS15mENsCXgGXJzwNTtrktqfcSUnpPACXAwmTZg9RzQaklvIAR7LlY3KbrDBQD85J/6+lA1wjq/ENgcVLexwi9ZdpUnYEnCddAdhK+vX+rOesIFAC/BZYTehb1qa9MGmJCRCRysTQNiYhILRQEIiKRUxCIiEROQSAiEjkFgYhI5BQEEh0zm21mGX/ouZmNS0YNfSLTx6px3B+Y2Q378pjSuuVmuwAirYmZ5XoYv6Uhvk3o970yk2US2Vs6I5AWycx6Jd+mf5mMT/9HM9s/Wbb7G72ZdU+GnsDMxpjZdDN73sxWmtnVZnZ9Mmjb62Z2YMohRpvZq8m498cn23dIxor/a7LNqJT9/tbMngf+mKas1yf7WWhm1yXzJhIGjnvOzL5TY/0cM/tJcpx3zOz/JPNHmNkcM5tmZu+Z2UQza5csuzgZe36hmd2Tsq/TzewtM3vbzF5KOUy/5Pe0wszGpdRvRrLuQjP72l78E0lbku277PTSK92LMExvBVCcvP8NMDqZng2UJNPdgVXJ9BjC3ZSdgELCqItXJsvuIwzQV7X9L5PpYSTDAQP/N+UYXQh3ondI9ltKyt2eKeU8Dng3Wa8jsAgYlCxbBXRPs81Y4LvJdD7h7uHehLumtxECJAd4kTBEwGGE4RcKCWfxLwP/lrxfA/RO9nVg8vMHwKvJvrsDG4E84PyqeifrHZDtf2e9WsZLTUPSkq109wXJ9HxCONTnFXffTBiHpRx4Ppn/LjAgZb0nAdx9jpl1NrMuhLHvz0lpXy8AeibTL7p7uoG7TgSmufsWADObCpwE/K2OMp4KDDCzC5L3BxDGkNlBGEdmRbKvJ5P97wRmu3tZMv8JQoDtAuZ40vRUo3wz3H07sN3M1gMHJ7+DnyZnFL9z97l1lFEioiCQlmx7yvQuYP9kuoI9zZoFdWxTmfK+kup/7zXHVqka2vd8d1+SusDMBhOGgU6nKY9ANOAad59Z4zgj6ihXbfupbYyYmr+7XHdfambHEcam+k8z+6O739HIsksbpGsE0hqtIjTJQGg6aYqvAZjZiYQHoJQTnux0TTKaI2Y2qAH7mQP8WzJiZgfgXKC+b9ozgassDCeOmR2RbAtwvIVRctslZfwz4cFDw5PrITmEp1H9CXgtmd872c+BNQ+UyswOA7a6++OEB8Ac24D6SQR0RiCt0U+B35jZpYT28qb4h5m9Sngk5DeTeXcSnoT2ThIGq4Cz69qJu79lZpMJozwCPOLudTULATxCaOZ6KzlOGaHNH8KH+93AMYSQmebulWY2HniFcBbwgrs/C2BmY4GpSXCsJzy2tDbHAD8xs0pCc9NV9ZRTIqHRR0VaiKRp6AZ3rzN8RJqbmoZERCKnMwIRkcjpjEBEJHIKAhGRyCkIREQipyAQEYmcgkBEJHL/C5uXHAIASBSVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(0, no_epochs), train_losses, color='blue')\n",
    "plt.plot(range(0, no_epochs), test_losses, color='red')\n",
    "plt.legend(['Train Loss', \"Test Loss\"], loc='upper right')\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy is 68.53146853146853%\n"
     ]
    }
   ],
   "source": [
    "y_pred = net(test_x)\n",
    "_, predicted = torch.max(y_pred.data, 1)\n",
    "correct = (predicted == test_y).sum().item()\n",
    "print(f\"Accuarcy is {100. * correct / len(test_x)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNB7ogddopYqmFoUzkoa6YX",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "4_PyTorch_Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
